/**
 * Test Improved Fallback Mechanism
 */

import { HybridModelClient } from './dist/core/hybrid-model-client.js';
import chalk from 'chalk';

async function testImprovedFallback() {
  console.log(chalk.blue('\nüîß Testing Improved Fallback Mechanism\n'));
  
  let hybridClient = null;
  
  try {
    // Initialize hybrid client
    console.log(chalk.yellow('üîÑ Initializing hybrid client...'));
    hybridClient = new HybridModelClient({
      autoLoadConfig: true,
      enableFallback: true,
      enableLearning: true
    });

    await new Promise(resolve => setTimeout(resolve, 3000));
    console.log(chalk.green('‚úÖ Hybrid client ready\n'));

    // Test simple prompt that should route to LM Studio (but will fail) and fallback to Ollama
    console.log(chalk.cyan('üß™ Testing LM Studio ‚Üí Ollama Fallback'));
    console.log(chalk.gray('   Expecting: LM Studio fails, automatically falls back to Ollama\n'));
    
    const startTime = Date.now();
    
    try {
      const response = await hybridClient.generateResponse(
        'Create a simple JavaScript function that adds two numbers',
        {},
        { enableEscalation: true }
      );

      const responseTime = Date.now() - startTime;
      
      console.log(chalk.green(`‚úÖ Response received in ${responseTime}ms`));
      console.log(`üéØ Provider: ${response.provider}`);
      console.log(`üìä Confidence: ${response.confidence.toFixed(2)}`);
      console.log(`üìà Escalated: ${response.escalated ? 'Yes' : 'No'}`);
      console.log(`üìù Content length: ${response.content.length} chars`);
      console.log(`üí≠ Preview: "${response.content.substring(0, 150)}..."`);
      
      if (response.metadata.originalProvider) {
        console.log(chalk.yellow(`üîÑ Fallback occurred: ${response.metadata.originalProvider} ‚Üí ${response.provider}`));
        console.log(`   Reason: ${response.metadata.escalationReason}`);
      }
      
      // Analyze quality
      const hasFunction = response.content.includes('function') || response.content.includes('=>');
      const hasAddition = response.content.includes('+') || response.content.includes('add');
      const hasReturn = response.content.includes('return');
      
      console.log(chalk.cyan('\nüìã Quality Analysis:'));
      console.log(`   Contains function syntax: ${hasFunction ? '‚úÖ' : '‚ùå'}`);
      console.log(`   Contains addition logic: ${hasAddition ? '‚úÖ' : '‚ùå'}`);
      console.log(`   Contains return statement: ${hasReturn ? '‚úÖ' : '‚ùå'}`);
      
      const qualityScore = [hasFunction, hasAddition, hasReturn].filter(Boolean).length;
      console.log(`   Quality Score: ${qualityScore}/3`);
      
      if (qualityScore >= 2 && response.content.length > 50) {
        console.log(chalk.green('\nüéâ Fallback mechanism working! Good quality response received.'));
      } else {
        console.log(chalk.yellow('\n‚ö†Ô∏è Fallback mechanism activated but response quality could be improved.'));
      }

    } catch (error) {
      const responseTime = Date.now() - startTime;
      console.log(chalk.red(`‚ùå Complete failure after ${responseTime}ms: ${error.message}`));
      
      if (error.message.includes('All providers failed')) {
        console.log(chalk.yellow('   Both LM Studio and Ollama failed - this indicates a configuration issue.'));
      }
    }

  } catch (error) {
    console.error(chalk.red('\n‚ùå Test setup failed:'), error);
  } finally {
    // Cleanup
    if (hybridClient) {
      try {
        await hybridClient.dispose();
        console.log(chalk.gray('\nüßπ Resources cleaned up successfully'));
      } catch (error) {
        console.log(chalk.yellow('\n‚ö†Ô∏è Cleanup warning:', error.message));
      }
    }
  }
}

// Run the test
testImprovedFallback().catch(console.error);